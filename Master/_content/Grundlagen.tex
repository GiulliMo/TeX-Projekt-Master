\chapter{Grundlagen}
\label{ch: Grundlagen}
	Für ein besseres Verständnis, der in Kapitel Konzept... angewandten Methoden, werden anbei die Grundlagen behandelt. Informationen zu der verwendeten Hard- und Software wurden bereits in der vorangegangenen Bachelorarbeit vermittelt. Aufgrund Anforderung A... ist während der praktischen Anwendung keine Änderung der Hardware vorgesehen.
 
	
 	\section{Neuronale Netze}
	\label{sec: ROS}
	
	Das Neuronennetz des menschlichen Gehirns dient als Vorbild für künstliche, neuronale Netze (KNN). Diese werden heutzutage als Lösung diverser Anwendungsprobleme angewendet, in denen komplexe Strukturen und Muster aus großen Datenmengen erkannt werden sollen. Das in diesem Projekt zugrundeliegende Bildverarbeitungsproblem besitzt die beschriebenen Eigenschaften und eignet sich somit für den Einsatz zur Erkennung von Personen. Anders als bei den meisten programmierten Applikationen ist die Ausgabe von KNN's lediglich probabilistisch. Beim vorliegenden, autonomen Logistikfahrzeug werden zur Personenerkennung derartige neuronale Netze verwendet.
	
		\subsection{Eigenschaften von neuronalen Netzen}
		
		Das Grundlage für die Eingabe in ein neuronales Netz ist die Skalierung der vorliegenden Daten auf eine definierte Größe. Diese wäre beispielsweise bei einem Anwendungsfall mit einer Audiospur die Frequenzspektren oder bei einem Bildverarbeitungsproblem die Pixel eines Bildes. Die skalierten Daten werden in einem Tensor gegeben der die Dimensionen der Eingabe hat. Somit unterteilt sich ein Bild in die drei Dimensionen, die Höhe, die Weite und die Farbwerte der Primärfarben pro Pixel.  
		
		/Bild Neuron
		
		Der grundlegende Aufbau eines neuronalen Netzes besteht aus miteinander verbundenen Schichten, die häufig aus Neuronen bestehen. Jedes Neuron verarbeitet im wesentlichen eingehende Zahlenwerte und gibt diese aus. Hierbei wird eine gewichtete Summe gebildet, die dann auf eine Aktivierungsfunktion angewendet wird.
		
		\begin{equation}
		s=\sum_{j=1}^n w_{ij}x_j
		\label{eq: Gewichtete Summe}
		\end{equation}
		\\
		
		Gleichung \ref{eq: Gewichtete Summe} zeigt das mathematische Modell der gewichteten Summe $s$. Das jeweilige Gewicht $w$ wird mit dem Index $j$ inkrementiert und mit dem dazugehörigen Eingang des Neurons $i$ multipliziert. Alle Produkte werden aufsummiert und ergeben die gewichtete Summe. Es gibt verschiedene Varianten der Aktivierungsfunktion, die je nach Netzart zur Anwendung kommen können. In welchen Eigenschaften sich neuronale Netze unterscheiden können, wird in Kapitel... beschrieben. Häufig werden für Aktivierungsfunktion Schwellwertfunktionen angewendet. \\
		
		/Bild neuronales netz
		\\
		
		In Abbildung... ist Grundstruktur eines neuronalen Netzes veranschaulicht. Neuronen sind hier als Kreise dargestellt und bilden in den beispielhaft vertikal veranschaulichten Formationen einzelne Schichten. Hierbei wird zwischen Eingabe-, Zwischen- und Ausgabeschichten unterschieden. Die Eingabeschicht nimmt Informationen in Form von Daten auf und gibt diese an die erste Zwischenschicht weiter. Die Anzahl der Zwischenschichten, oder auch verdeckte Schichten, ist in der Anwendung der neuronalen Netzen variabel. Am rechten Bildrand ist die Ausgabeschicht gezeigt, die die entsprechende Ausgabe des Netzes generiert.  
	
		\subsection{Lernprozess}
		Der Lernprozess von neuronalen Netzen zielt darauf hinaus, einer Netzstruktur ein gewünschtes Verhalten beizubringen. Genauer sollen die in Kapitel... beschriebenen Gewichte modifiziert werden. Dafür ist vor dem Lernprozess eine Trainingsmenge nötig. Im Falle einer Personenerkennung wäre beispielsweise ein Datensatz aus Bildern von Personen ein geeignete Trainingsmenge.\\
		
		Zunächst wird zwischen drei Lernverfahren unterschieden, dem unüberwachten Lernen, dem bestärkenden Lernen und dem überwachten Lernen. Beim unüberwachten Lernen erkennt das Netz selbst Muster und Klassen aus der eingegebenen Menge. Anders als beim unüberwachten Lernen, lernt das Netz beim bestärkten Lernen mit einer Rückmeldung. Diese enthält Informationen darüber, ob ein errechnetes Ergebnis einer Trainingseinheit richtig oder falsch ist. Das überwachte Lernen setzt eine Trainingsmenge voraus, die neben der Eingabedaten auch das dazugehörige korrekte Ergebnis enthält. So wird in der Vorwärtspropagation durch eine Eingabe eine entsprechende Ausgabe erzeugt und diese mit dem korrekten Ergebnis verglichen. Das KNN wird dann mithilfe des aus dem vorangegangenen Vergleich entstandenen Fehler korrigiert.\cite{Kriesel}\\
		
		Die meist genutzte Form des überwachten Lernens ist die Rückwärtspropagierung (engl. Backpropagation) oder Fehlerrückführung genannt \cite{Ertel}. Die mathematische Grundlage für dieses Lernverfahren sind Gradientenabstiegsverfahren. Durch die Fehlerrückführung werden Gewichte durch die Ausgabeschicht, die dann als Eingabeschicht interpretiert wird, mithilfe des Fehlervektors optimiert.\cite{Kriesel}
		
		\subsection{Unterscheidung von neuronalen Netzen}
		/handbuch ki
		
	
		
		\subsection{Evaluation neuronaler Netze}
			
		Die Ausgabe von neuronalen Netzen ist probabilistisch und nicht vorhersehbar. Folglich bestehen diverse Metriken für Evaluationen, die derartige Systeme messbar machen. 
		
	\section{Objekterkennung}
	\label{sec: Mecanumräder}
	Bei der visuellen Objekterkennung wird ein Objekt, das auf einem Bild gezeigt ist, mit einer gewissen Wahrscheinlichkeit inklusive der Position in der Abbildung erkannt. Die drei Abstraktionsebenen einer solchen Erkennung unterteilen sich in Bildklassifikation, Objektlokalisierung und semantische Segmentierung ...2014Bild. Letzteres kommt in dieser Arbeit nicht zur Anwendung und wird aufgrunddessen im Folgenden nicht behandelt. Weiterhin wird ebenfalls die Objekterkennung durch neuronale Netze betrachtet und in Kapitel... verglichen.
	
		\subsection{Bildklassifikation}
		Die Bildklassifikation beschreibt eine Zuweisung von Objektkategorien zu einem gegebenen Bild. Mithilfe einer Merkmalsextraktion werden Merkmalsvektoren extrahiert und können so in einem Klassifikator berechnet werden. Ein Gängiges Verfahren zur Merkmalsgewinnung ist das sogenannte Histogram of oriented gradients (HOG). Bei diesem Verfahren werden in einem Bild auftretende Intensitäten geprüft und so Kanten und Ecken als Histogramm gespeichert. Die Support Vektor Maschine ist ein typischer Funktionsapproximator für eine Objektklassifikation. Es handelt sich hierbei um ein Verfahren, das Klassen durch eine sogenannte Hyperebene voneinander trennt. Diese Methode hat sich vor allem aufgrund ihrer kurzen Rechenzeit durchgesetzt.
			
		\subsection{Objektlokalisierung}
		Wie in Kapitel... beschrieben, soll die Ausgabe einer Objekterkennung auch den Ort eines Objektes enthalten. Für jedes erkannte Objekt wird ein Rechteck in Form von Pixelkoordinaten erzeugt, das den Interessensbereich beschreibt.
	
		\subsection{Objekterkennung durch neuronale Netze}
		
		Die bisher besten Ergebnisse in der Bildverarbeitung im Zusammenspiel mit neuronalen Netzen wurden durch \textit{Convolutional Neural Network} (CNN) ermöglicht. Anders als bei den bereits erwähnten Methoden geschieht die Merkmalsextraktion hierbei innerhalb des Netzes. Derartige Netzwerke nutzen bestimmte Zwischenschichten zur Verarbeitung der Eingangsdaten. Grundlegend wird hier zwischen der Klassifikation durch eine vorangegangene Merkmalsextraktion unterschieden.\\ 
		
		/bild merkmalsextraktion\\
		
		Die Reihenfolge der Schichten der Merkmalsextraktion setzt sich aus einer Konvolutionsschicht und einer weiteren Schicht zusammen, die mithilfe von Pooling eine nichtlineare Optimierung der Daten vornimmt. Dabei kann sich die genannte Reihenfolge beliebig oft wiederholen. Während der Konvolution, oder auch Faltung genannt, werden eingehende Daten in Filter, sogenannte Kernels, eingegeben. Diese extrahieren bestimmte Merkmale, dabei können sich die Filter je Schicht ändern. So können verschiedenee Schichten diverse Merkmale extrahieren. Zu einer Konvolutionsschicht gehört auch die \textit{Rectified linear unit} (ReLU) Funktion. Durch sie werden negative Werte zu Null korrigiert und positive Werte erhalten. Dies ermöglicht schnelleres und effektiveres Training. Beim Pooling werden eingehende Matrizen minimiert. Gleichzeitig gehen die aussagekräftigsten Merkmale jedoch nicht verloren. \\
		
		/bild Klassifikation\\
		
		Für die Klassifikation der Daten setzten sich die letzten Schichten aus einer Glättungsschicht, einer vollständig verbundnen Schicht und einer Softmax Schicht. Durch die Glättungsschicht werden die matrizen aus der letzten Poolingschicht zu einem Vektor geformt. Nur so können die Daten in die vollständig verbundene schicht eingegeben werden. Diese gibt einen $K$-dimensionalen Vektor aus, wobei $K$ für die Anzahl der ausgegebenen Klassen steht. Durch die folgende Softmax-Schicht wird der Vektor in einem Zahlenbereich von Null bis Eins transformiert. An dieser Stelle sind alle Daten vollständig bearbeitet und werden als Vektor aus dem CNN ausgegeben. Jedes Element wird als Konfidenz der jeweiligen Klasse interpretiert. 
		
		Die Artenvielfalt der CNNs ist sehr breit gefächert. Jedes Netzwerk unterscheidet sich in der jeweiligen Architektur der Schichten. Durch die Änderung verschiedener Parameter, beispielsweise bei der Faltung oder beim Pooling, können CNNs im Einsatz jeweils anders reagieren. Hierbei entscheidet man bei der Auswahl des Modells häufig unter den Gesichtspunkten Bearbeitungszeit, Genauigkeit und je nach Anwendungsfall spielt der Speicherplatz ebenfalls eine große Rolle.
	

			
	\section{Zustandsautomat}
	\label{sec: Zustandautomat}
	Die Idee der Nutzung eines Zustandsautomaten oder auch endlicher Automat (EA) ergab sich im Laufe der Entwicklungsphase. In der in Kapitel ... erwähnten Bachelorarbeit werden diverse Modi beschrieben, die den Aufruf von unterschiedlichen ROS-Knoten vorraussetzen. Aufgrund der Analogie zwischen den beschriebenen Modi und der Zustände eines Zustandsautomaten wird die Nutzung eines solchen Automaten begründet. Im Folgenden wird auf die Eigenschaften eines endlichen Automats eingegangen.\\
	
	Im Allgemeinen geht es bei einem Zustandsautomaten um die Beschreibung der Zustände (engl. States) eines Objekts. Dabei stellt das Objekt meist das Gesamtsystem dar, etwa ein Getränkeautomat oder wie dieser Arbeit autonomes Fahrzeug. States sind durch Bedingungen verknüpft und lösen während sogenannter Ereignisse eine Transition aus, die den Wechsel des Zustands ausübt. Weiterhin Bilden die Zustände in ihrer Gesamtheit den Lebenszyklus des Objekts. Ein Getränkeautomat befindet sich bekanntermaßen beim Eintreffen eines Kunden in einer Art Bereitschaft. Übertragen auf die Theorie eines Zustandsautomaten wäre dies ein Bereitschaftszustand. Die Auswahl des Getränks und die Eingabe des entsprechenden Geldbetrags können beispielhaft als Ereignisse interpretiert werden. Somit wird ein Transition durchgeführt und der Zustand der Getränkeausgabe wird losgetreten. Wurde das Getränk ausgegeben und entnommen, geschieht der Wechsel in den Bereitschaftszustand und der beschriebene Zyklus ist komplettiert.\\
	
	Seit dem Bestehen der endlichen Automaten haben sich in der Praxis zwei Typen durchgesetzt. Mealy und Moore Automaten unterscheiden sich grundlegend in ihrem Verhalten und können durch folgende Gleichungen beschrieben werden.\\
	
	\begin{equation}
		\alpha_{t+1}=\phi(\zeta_t,\alpha_t)\text{    mit    t}\in\mathbb{N}
		\label{eq: transferfct}
	\end{equation}

	\begin{equation}
		\gamma_t=\psi(\zeta_t,\alpha_t)\text{    mit    t}\in\mathbb{N}
		\label{eq: transferfct}
	\end{equation}
	\\
	In den Gleichung ... beschreibt $\varphi$ die Transitionsfunktion und $\psi$ die Ausgabefunktion des Mooreautomats. Die Transition steht in Abhängigkeit von $\zeta_t $, die aktuelle Eingabe, und $\alpha_t$, der aktuelle Zustand selbst. Mithilfe der Transitionsfunktion lässt sich der Zustand bestimmen, der im folgenden Zeitschritt $t$ angestrebt werden soll. Der Ausgang des Moore Automaten wird durch die Ausgangsfunktion $psiup$ berechnet. Diese hängt genau wie die Transitionsfunktion von der Eingabe und dem Zustand zum Zeitpunkt $t$ ab. \\
	
	\begin{equation}
		\alpha_{t+1}=\phi(\zeta_t,\alpha_t)\text{    mit    t}\in\mathbb{N}
		\label{eq: transferfct}
	\end{equation}
	
	\begin{equation}
		\gamma_t=\psi(\alpha_t)\text{    mit    t}\in\mathbb{N}
		\label{eq: transferfct}
	\end{equation}
	\\
	
	Beim Vergleich der beiden Gleichungen ... und ... stellt sich heraus, dass die Ausgangsfunktion $psi$ in der Beschreibung des Verhaltens eines endlichen Automaten durch Moore lediglich vom Ausgang zum Zeitpunkt $t$ abhängig ist.
	
	Eine Unterkategorie der Finiten Automaten ist der Hierarchische Zustandsautomat. Die Besonderheit hierbei ist die Zusammensetzung aller vorangegangenen Zustände eines aktiven Zustands. Diese sind bei der hier beschriebenen hierarchisch aufgebauten Maschine nämlich ebenfalls aktiv. So besteht die Möglichkeit eines aufeinander aufbauenden Endzustands. 
	
	
		
		
	\section{Bestimmung von Positionskoordinaten}
		Während der Durchführung autonomer Fahr- bzw. Logistikaufgaben können diverse Probleme auftreten, die eine erfolgreiche Bearbeitung verhindern können. Beispielsweise können Türen geschlossen sein oder Gegenstände die geplante Route blockieren. Da das ALF nicht über die technischen Möglichkeiten besitzt derartige Problemstellungen zu lösen, müssen Menschen Abhilfe schaffen. Für diese Zwecke ist die Kenntnis über die letzte Position der erfassten Personen realtiv zur statischen Karte  notwendig. Anstehende Fahraufgaben werden, bedingt durch das Vorgängerprojekt, mithilfe des Robot Operating Systems gelöst. Personen können folglich als Position in das ROS Netzwerk veröffentlicht. Dies ermöglicht dem Roboter die veröffentlichten Positionen anzufahren. Die Eintragung der Position in die statische Karte setzt die Beschreibung der Position als Koordinaten vorraus. Für die Bestimmung der Positionskoordinaten wird ein zweidimensionales Bild und die dazugehörigen Tiefeninformationen genutzt. Die Koordinate xloc beschreibt hier die longitudinale Entfernung von der Kamera zur Person. Eingehende laterale Distanzen werden durch die Koordinate yloc dargestellt.
		
	\begin{figure}[H]
		\centering
			\begin{tikzpicture}[]
				\draw[<->] (-5,0) -- (5,0) node[right] {$y$};
				\draw[->] (0,-1.2) -- (0,7) node[above] {$x$};
				\draw[thin,-] (0,0) -- (4,6) node[above] {$f_{r}$};
				\draw[thin,-] (0,0) -- (-4,6) node[above] {$f_{l}$} ;
				\draw[densely dotted] (1,1.5) -- (-1,1.5) node[left] {$Bild$};
				\filldraw [black] (1.5,4.5) circle (2pt);
				\draw[dashed] (0,0) -- (1.5,4.5) node[above] {$Objekt$};
				\draw[very thick] (0,4.5) -- (1.5,4.5) node[left] {};
				\draw[very thick] (0,0) -- (0,4.5) node[left] {};
				\draw[very thick]  (0,3) node[left] {$x_{loc}$};
				\draw[very thick]  (0.75,4.0) node[above] {$y_{loc}$};
				\draw[very thick]  (0,1) node[left] {$x_{f}$};
			\end{tikzpicture}
		
		\caption{(a) Die Abbildung zeigt die Übergangsfunktion $h(t)$ eines Verzögerungsglieds erster Ordnung als Antwort auf die sprungförmige Eingangsgröße $u(t)$ mit $\hat{u}=1$. (b) Die Impulsantwort auf das Eingangssignal $\delta(t)$. Zwischen den Funktionen $h(t)$ und $g(t)$ besteht der Zusammenhang \mbox{$g(t)=\frac{\mathrm d}{\mathrm d t}\:h(t)$}.}
		\label{fig: antworten}
	\end{figure}
	     
	

