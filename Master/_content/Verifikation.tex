\chapter{Evaluation}
\label{ch: Verifikation}
Zur Evaluation der künstlichen neuronalen Netze wird eine anwendungsorientierte \textit{Benchmark} durchgeführt. Hierbei wird anhand der in Kapitel \ref{subsec: Entwickeltes neuronales Netz} beschriebenen Datensätze die \textit{Precision-Recall}-Methode angewendet. Weiterhin werden die Benchmarks auf dem integrierten Computer des ALFs und einem eingebettetem System ausgeführt. Als eingebettetes System wird ein \textit{Raspberry Pi 3 Model B} verwendet. Die Eckdaten des integrierten Computers sind in der Masterthesis von M.Sc. \textit{Dominik Eickmann} und M.Sc. \textit{Dennis Hotze} dargestellt \cite{alf}. Es ist keine geräteübergreifende Veränderung der Genauigkeit je Netz zu erwarten. Jedoch können so die Bearbeitungszeiten pro Bild für unterschiedliche Hardware verglichen werden. Eine präzise Auflistung aller gemessenen Analysezeiten ist in Tabelle \ref{fig: zeitentab} präsentiert. \\

Insgesamt werden für den Test durch \textit{COCO-Datensatz} 12755 Bilder aus dem Trainingsdatensatz verwendet. Der technische Hintergrund hierfür ist in Kapitel \ref{subsec: Entwickeltes neuronales Netz} zu finden. Als Vergleich analysiert jedes Netz auch den eigenen Datensatz. So kann die Performance am Einsatzort des ALFs an der Hochschule Bochum evaluiert werden. Jedes Bild wird für die verwendeten, neuronalen Netze auf eine Pixelgröße von $300 \times 300$ skaliert. Für die Evaluation des \textit{HoGs} wird eine höhere Auflösung gewählt. Hierbei wird eine Seite des Bildes softwareseitig auf 400 Pixel begrenzt. \\

Der in Grundlagenkapitel \ref{subsec: evaluation neuronaler netze} beschriebene mAP-Wert wird häufig auf Objekterkennungssystemen mit multiplen Klassen angewendet. Die hier entwickelte Personenerkennung soll jedoch lediglich die Klasse \textit{Person} erkennen. Somit ist der mAP-Wert in diesem Fall der Mittelwert eines Messwerts und kann als Integral der \textit{Precision-Recall}-Kurve angesehen werden. Im Verlauf der Evaluation der angewendeten Systeme wird mithilfe einer Berechnungssoftware jeweils der mAP-Wert berechnet.
 
\input{Bilder/hog1}

Die Kombination aus \textit{HoG} und \textit{SVM} erreicht in der Benchmark die in Abbildung \ref{fig: hog1} präsentierten Ergebnisse. Der \textit{mAP}-Wert liegt für den eigenen Datensatz bei 0,16 und für den \textit{COCO}-Datensatz bei 0,07 Bei der Durchsicht der eingetragenen Begrenzungsrahmen ist aufgefallen, dass diese verhältnismäßig groß ausfallen. Somit könnte der \textit{IoU}-Wert entsprechend niedrig sein und zu diesem Ergebnis führen. Diese Beobachtung kann der \textit{HoG-SVM}-Methode zugrunde liegen. Mit den entsprechende Optimierungen wurden die \textit{Precision-Recall} Werte für dieses System maximiert und sind in der obigen Abbildung dargestellt.


\input{Bilder/cocossdmobilenetv1tflite}

Eine deutliche Steigerung hinsichtlich der Geschwindigkeit im Vergleich zur \textit{HoG-SVM}-Methode wird durch das quantisierte \textit{MobileNet V1 SSD} Netz erreicht. Die Berechnung des Integrals der \textit{Precision-Recall}-Kurve ergab für den eigenen Datensatz einen Wert von 0,68 und für den \textit{COCO}-Datensatz 0,46. Dieses Netz ist in der Lage 90 verschiedene Klassen zu erkennen. Hierbei nimmt das Netz jedoch lediglich 4 MB Speicherplatz ein.

\input{Bilder/ownssdmobilenetv1}

Das in Abbildung \ref{fig: ownnetv1} gezeigte \textit{MobileNet V1 SSD}-Netz ist darauf trainiert Personen zu erkennen. Die dargestellte Architektur weißt einen \textit{mAP}-Werte von 0,79 für den eigenen Datzensatz und 0,56 für den \textit{COCO}-Datensatz auf.

\input{Bilder/ownnetv2}

In Darstellung \ref{fig: ownnetv2} werden die \textit{Precision-Recall}-Kurven eines \textit{MobileNet V2 SSD} gezeigt. Das Verhaltensmuster dieses Netzes ist ebenfalls auf eine Personenerkennung beschränkt, um enthaltene Parameter und den damit verbundenen Speicherplatz zu reduzieren. Die \textit{mAP}-Werte liegen bei 0,78 für den eigenen Datensatz und 0,54 für den \textit{COCO}-Datensatz. 

\input{Bilder/ssdmobilenetv2tflite}

Abbildung \ref{fig: ssdmobilenetv2} zeigt die \textit{Precision} und \textit{Recall} Kurve einer \textit{MobileNet V2 SSDLite} Architektur. Auffällig hierbei, ist die konstant hohe Genauigkeit $p(t)$. Diese liegt bis zu einem \textit{Recall}-Wert von circa 0,8 zwischen 0,9 und 1. Für die Anwendung auf den eigenen Datensatz erreicht diese Architektur eine mittlere Durschnittsgenauigkeit von 0,77. Angewendet auf den \textit{COCO}-Datensatz liegt der Wert bei 0,54. 

 
\input{Bilder/ownnetv2ssdlite}
 
  
Die \textit{Precision-Recall}-Kurven der \textit{MobileNet V2 SSDLite} Architektur sind in der Grafik \ref{fig: ownnetv2ssdlite} abgebildet. \\

Nachfolgend werden die Benchmarkergebnisse der untersuchten Objekterkennungssysteme gegenübergestellt. Der Vergleich dient zur Veranschaulichung der gemessenen \textit{Precision-Recall}-Leistung je Datensatz. In Abbildung \ref{fig: genauigkeitsvergleich} werden die untersuchten \textit{MobileNet}-Architekturen anhand des eigenen Datensatzes verglichen. So kann eine Aussage darüber getroffen werden, ob die Systeme ortsabhängig ein anderes Verhaltensmuster an aufzeigen. Es kann beispielsweise passieren, dass die Netze aufgrund prägnater Eigenschaften der Umgebung am Standort der Hochschule Bochum verschieden reagieren. Eine allgemeine Aussage über die Genauigkeiten kann anhand der Darstellung \ref{fig: genauigkeitsvergleichcoco} getroffen werden. Für die Verallgemeinerung sorgt hierbei der \textit{COCO}-Datensatz. Dieser enthält anders als der eigene Datensatz Bilder von verschiedenen Orten.     


\input{Bilder/gesamtvergleich}

\input{Bilder/gesamtvergleichcoco}

Bei den Auswertungen der \textit{Precision-Recall}-Werte erreichte die Kombination aus \textit{HoG} und \textit{SVM} im Vergleich zu den \textit{MobileNet}-Netzen niedrige Ergebnisse. In den Vergleichsgrafiken \ref{fig: genauigkeitsvergleich} und \ref{fig: genauigkeitsvergleichcoco} wird das System aufgrunddessen nicht weiter betrachtet. Es ist zu beachten, dass die verwendete Auswertungssoftware den \textit{Recall} in einer Schrittweite von 0,25 ausgibt. Überwiegend fällt das quantisierte \textit{MobileNet V1 SSD}-Netz in Abbildung \ref{fig: genauigkeitsvergleich} auf. Die Kurve zeigt einen anderen Verlauf als die anderen Kandidaten. Das Verhältnis aus \textit{Precision} und \textit{Recall} reduziert sich bei derartigen Strukturen durch eine Quantisierung. Netzoptimierungen wie die zweite Version des \textit{MobileNets} oder der Weiterentwicklung des \textit{SSDs} zeigen vorwiegend eine Beschränkung der \textit{Recall}-Werte. Jedoch gibt es im Verlauf der \textit{Precision}-Werte keine nenneswerte Unterschiede. 

\input{Bilder/zeitenvergleich}

Die Berechnungszeit pro Bild des eigenen Datensatzes aller untersuchten Objekterkennungssysteme ist in der Tabelle in Abbildung \ref{fig: zeitentab} präsentiert. 

\input{Bilder/genauigkeiten}

